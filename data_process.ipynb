{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08864259",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20b65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import time\n",
    "\n",
    "sys.path.append('eda_nlp/')\n",
    "from eda_nlp.augment import gen_eda\n",
    "from eda_nlp.eda import get_only_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c527c6",
   "metadata": {},
   "source": [
    "### Unimportant for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de33b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "eval_ent_dict = {\"O\": 0,\n",
    "                 \"Term\": 1,\n",
    "                 \"Definition\": 2,\n",
    "                 \"Alias-Term\": 3,\n",
    "                 \"Referential-Definition\": 4,\n",
    "                 \"Referential-Term\": 5,\n",
    "                 \"Qualifier\": 6}\n",
    "\n",
    "inv_eval_ent_dict = {0: \"O\",\n",
    "                     1: \"Term\",\n",
    "                     2: \"Definition\",\n",
    "                     3: \"Alias-Term\",\n",
    "                     4: \"Referential-Definition\",\n",
    "                     5: \"Referential-Term\",\n",
    "                     6: \"Qualifier\"}\n",
    "\n",
    "\n",
    "keep_def_prob = 1\n",
    "keep_O_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1497aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_token(token, tokenizer, lang_model):\n",
    "    if \"roberta\" in lang_model:\n",
    "        return tokenizer.decode(token).replace(\" \", \"\")\n",
    "    elif \"scibert\" in lang_model:\n",
    "        token_word = tokenizer.decode(token).lower()\n",
    "        return token_word if token_word[:2] != \"##\" else token_word[2:]\n",
    "    elif \"xlnet\" in lang_model:\n",
    "        return tokenizer.decode(token)\n",
    "    elif \"albert-base\" in lang_model:\n",
    "        return tokenizer.decode(token)\n",
    "    elif \"bert\" in lang_model:\n",
    "        token_word = tokenizer.decode(token)\n",
    "        return token_word if token_word[:2] != \"##\" else token_word[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f6e77",
   "metadata": {},
   "source": [
    "## Preprocessing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0daea101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_weird_letters(word, lang_model):\n",
    "    replacements_chars = [(\"ö\", \"o\"), (\"é\", \"e\"), (\"ê\", \"e\"), (\"ü\", \"u\"),\n",
    "                          (\"ó\", \"o\"), (\"â\", \"a\"), (\"ä\", \"a\"), (\"à\", \"a\"),\n",
    "                          (\"ç\", \"c\"), (\"ï\", \"i\"), (\"ô\", \"o\"), (\"û\", \"u\"),\n",
    "                          (\"ÿ\", \"y\"), (\"á\", \"a\")]\n",
    "    \n",
    "    if \"scibert\" in lang_model:\n",
    "        word = word.lower()\n",
    "        \n",
    "        for init_char, repl_char in replacements_chars:\n",
    "            word = word.replace(init_char, repl_char)\n",
    "    elif \"albert\" in lang_model:\n",
    "        word = word.lower()\n",
    "    elif \"xlnet\" in lang_model:\n",
    "        for init_char, repl_char in replacements_chars:\n",
    "            word = word.replace(init_char, repl_char)\n",
    "            word = word.replace(init_char.upper(), repl_char.upper())\n",
    "        \n",
    "    return word\n",
    "\n",
    "\n",
    "def correct_punctuation(word, lang_model):\n",
    "    word = word.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\").replace(\"’\", \"'\").replace(\"‘\", \"'\") \\\n",
    "                               .replace(\",\", \",\").replace(\"⋅\", \"*\").replace(\"—\", \"-\").replace(\"`\", \"'\")\n",
    "                               # replace(\"…\", \"...\").replace(\"º\", \"\")\n",
    "    \n",
    "    if \"scibert\" in lang_model:\n",
    "        word = word.replace(\"º\", \"*\")\n",
    "    elif \"roberta\" in lang_model:\n",
    "        word = word.replace(\"º\", \"\")\n",
    "    elif \"xlnet\" in lang_model:\n",
    "        word = word.replace(\"…\", \"...\")\n",
    "                               \n",
    "    return word\n",
    "\n",
    "\n",
    "def remove_greek(word, lang_model, tokenizer):\n",
    "    greek_alphabet = 'αβγδεζηθικλμνξοπρςστυφχψω' + 'αβγδεζηθικλμνξοπρςστυφχψω'.upper() + \"∆\"\n",
    "    \n",
    "    for letter in greek_alphabet:\n",
    "        word = tokenizer.unk_token if letter in word else word\n",
    "        \n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c0399",
   "metadata": {},
   "source": [
    "## Main processing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0240bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path, data_kind=\"train\"):\n",
    "    \n",
    "    cols = [\"SentenceNumber\", \"Word\", \"Tag\"]\n",
    "    rows = []\n",
    "    sentence_counter = 1\n",
    "    \n",
    "    number_of_files = len(os.listdir(path))\n",
    "\n",
    "    print(\"Tracking Progress: Current File Number / Total Files\")\n",
    "    for file_ct, filename in enumerate(os.listdir(path)):\n",
    "        \n",
    "        print(file_ct+1, \"/\", number_of_files, end=\", \")\n",
    "        \n",
    "        with open(os.path.join(path, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "\n",
    "            for line in file:\n",
    "                if line != \"\\n\":\n",
    "                    tokens = line.split()\n",
    "                    word, entity = tokens[0], tokens[4] \n",
    "\n",
    "                    rows.append({\"SentenceNumber\": sentence_counter, # if it is not the above than append to dataset\n",
    "                                 \"Word\": word,\n",
    "                                 \"Tag\": entity})\n",
    "                else:\n",
    "                    sentence_counter += 1\n",
    "            \n",
    "    # creating dataframe\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "    # Writing dataframe to csv\n",
    "    df.to_csv(\"data/{kind}.csv\".format(kind=data_kind))\n",
    "    \n",
    "    # Adding EntityNumber field - needed for augmentation\n",
    "    df['EntityNumber'] = None\n",
    "\n",
    "    df.loc[(df['Tag'] != df['Tag'].shift(1)) & (df['Tag'].str[0] != 'I'), 'EntityNumber'] =\\\n",
    "        np.arange(len(df.loc[(df['Tag'] != df['Tag'].shift(1)) & (df['Tag'].str[0] != 'I')]))\n",
    "    df['EntityNumber'] = df['EntityNumber'].fillna(method='ffill')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93bd4c9",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c825bd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking Progress: Current File Number / Total Files\n",
      "1 / 67, 2 / 67, 3 / 67, 4 / 67, 5 / 67, 6 / 67, 7 / 67, 8 / 67, 9 / 67, 10 / 67, 11 / 67, 12 / 67, 13 / 67, 14 / 67, 15 / 67, 16 / 67, 17 / 67, 18 / 67, 19 / 67, 20 / 67, 21 / 67, 22 / 67, 23 / 67, 24 / 67, 25 / 67, 26 / 67, 27 / 67, 28 / 67, 29 / 67, 30 / 67, 31 / 67, 32 / 67, 33 / 67, 34 / 67, 35 / 67, 36 / 67, 37 / 67, 38 / 67, 39 / 67, 40 / 67, 41 / 67, 42 / 67, 43 / 67, 44 / 67, 45 / 67, 46 / 67, 47 / 67, 48 / 67, 49 / 67, 50 / 67, 51 / 67, 52 / 67, 53 / 67, 54 / 67, 55 / 67, 56 / 67, 57 / 67, 58 / 67, 59 / 67, 60 / 67, 61 / 67, 62 / 67, 63 / 67, 64 / 67, 65 / 67, 66 / 67, 67 / 67, "
     ]
    }
   ],
   "source": [
    "kind = \"test\" # train / validation / test\n",
    "\n",
    "base_path = r\"C:\\Users\\pkozminski\\Documents\\Studia\\deft_corpus\\data\"\n",
    "if not os.path.exists(base_path):\n",
    "    base_path = \"C:/Users/Hasan/Desktop/Barcelona_Data/FIB_Courses/HLE/Project/DeftEval2020/code/deft_corpus/data\"\n",
    "if not os.path.exists(base_path):\n",
    "    raise ValueError(\"Provide an existing path to the data directory\")\n",
    "\n",
    "if kind==\"train\":\n",
    "    path = os.path.join(base_path, r\"deft_files\\train\")\n",
    "elif kind==\"validation\":\n",
    "    path = os.path.join(base_path, r\"deft_files\\dev\")\n",
    "elif kind==\"test\":\n",
    "    path = os.path.join(base_path, r\"test_files\\labeled\\subtask_2\")\n",
    "else:\n",
    "    print(\"For the data kind to process, please specify one of train/validation/test\")\n",
    "    \n",
    "df = process_data(path, data_kind=kind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdef246",
   "metadata": {},
   "source": [
    "Term\n",
    "Definition\n",
    "Alias-Term\n",
    "Referential-Definition\n",
    "Referential-Term\n",
    "Qualifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b19cfdc",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "The augmentation will be performed by EDA ([Easy Data Augmentation](https://github.com/jasonwei20/eda_nlp)) procedure, involving only synonym replacing method.\n",
    "\n",
    "Data transformations are as follows:\n",
    "- The tokens corresponding to the entities are pasted into one sequence\n",
    "- Sequences are passed into the augmenting function and replicated several times\n",
    "- All the replicated versions are later ordered in the same order as at the beginning\n",
    "- The sequences are tokenized with `word_tokenize` function\n",
    "\n",
    "A drawback is that the sentences lose interpunction and upper letters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2736ee9",
   "metadata": {},
   "source": [
    "#### Main part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f56526b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking Progress: Current File Number / Total Files\n",
      "1 / 80, 2 / 80, 3 / 80, 4 / 80, 5 / 80, 6 / 80, 7 / 80, 8 / 80, 9 / 80, 10 / 80, 11 / 80, 12 / 80, 13 / 80, 14 / 80, 15 / 80, 16 / 80, 17 / 80, 18 / 80, 19 / 80, 20 / 80, 21 / 80, 22 / 80, 23 / 80, 24 / 80, 25 / 80, 26 / 80, 27 / 80, 28 / 80, 29 / 80, 30 / 80, 31 / 80, 32 / 80, 33 / 80, 34 / 80, 35 / 80, 36 / 80, 37 / 80, 38 / 80, 39 / 80, 40 / 80, 41 / 80, 42 / 80, 43 / 80, 44 / 80, 45 / 80, 46 / 80, 47 / 80, 48 / 80, 49 / 80, 50 / 80, 51 / 80, 52 / 80, 53 / 80, 54 / 80, 55 / 80, 56 / 80, 57 / 80, 58 / 80, 59 / 80, 60 / 80, 61 / 80, 62 / 80, 63 / 80, 64 / 80, 65 / 80, 66 / 80, 67 / 80, 68 / 80, 69 / 80, 70 / 80, 71 / 80, 72 / 80, 73 / 80, 74 / 80, 75 / 80, 76 / 80, 77 / 80, 78 / 80, 79 / 80, 80 / 80, "
     ]
    }
   ],
   "source": [
    "df_train = process_data(os.path.join(base_path, r\"deft_files\\train\"), data_kind='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4962da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sentence(s):\n",
    "    return ''.join(list(map(lambda x: ' ' + x if x[0].isalpha() else x, s)))\n",
    "\n",
    "def tokenize_sentences_to_df(df):\n",
    "    df_augmented_expanded = pd.DataFrame(columns=['SentenceNumber', 'Version', 'Tag', 'Word'])\n",
    "    for i, row in df.iterrows():\n",
    "        sentence_tokens = word_tokenize(row['Sentence'])\n",
    "        labels = [row['Label']] + ['I' + row['Label'][1:]]*(len(sentence_tokens)-1)\n",
    "        df_augmented_expanded = pd.concat((\n",
    "            df_augmented_expanded,\n",
    "            pd.DataFrame({\"EntityNumber\": row['EntityNumber'],\n",
    "                          \"SentenceNumber\": row['SentenceNumber'],\n",
    "                          \"Version\": row['Version'],\n",
    "                          \"Tag\": labels,\n",
    "                          \"Word\": sentence_tokens})\n",
    "        ), ignore_index=True)\n",
    "    return df_augmented_expanded\n",
    "\n",
    "def prepare_original_dataset_to_add_augmentation(df, version, condition):\n",
    "    df['Version'] = version\n",
    "    return df.loc[condition]\n",
    "\n",
    "def oversample(input_df, n):\n",
    "    \"\"\"\n",
    "    input_df must contain columns EntityNumber, SentenceNumber, Label, and Sentence\n",
    "    n - number of each sentence duplications\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(columns=['EntityNumber', 'SentenceNumber', 'Label', 'Sentence', 'Version'])\n",
    "    for i, row in input_df.iterrows():\n",
    "        entity_number = row['EntityNumber']\n",
    "        sentence_number = row['SentenceNumber']\n",
    "        label = row['Label']\n",
    "        sentence = row['Sentence']\n",
    "        aug_sentences = [sentence]*n\n",
    "        for aug_i, aug_sentence in enumerate(aug_sentences):\n",
    "            result = pd.concat((result, pd.DataFrame({\"EntityNumber\": entity_number,\n",
    "                                                      \"SentenceNumber\": sentence_number,\n",
    "                                                      \"Label\": label,\n",
    "                                                      \"Sentence\": aug_sentence,\n",
    "                                                      \"Version\": aug_i\n",
    "                                                      }, index=[0])),\n",
    "                               ignore_index=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "def add_data(df,\n",
    "             label,\n",
    "             mode = 'augmentation',\n",
    "             augment_only_this_label = False,\n",
    "             alpha_sr = 0.5,\n",
    "             num_adds = 10):\n",
    "    \"\"\"\n",
    "    Function adding the data\n",
    "    \"\"\"\n",
    "    \n",
    "    if mode == 'augmentation':\n",
    "        gen_fun = gen_eda\n",
    "        gen_fun_args = dict(alpha_sr=alpha_sr, num_aug=num_adds, alpha_ri=0, alpha_rs=0, alpha_rd=0)\n",
    "    elif mode == 'oversampling':\n",
    "        gen_fun = oversample\n",
    "        gen_fun_args = dict(n=num_adds)\n",
    "        augment_only_this_label = True\n",
    "    else:\n",
    "        raise ValueError('Wrong mode')\n",
    "\n",
    "    # All tokens marked with the label\n",
    "    df_label = df.loc[df['Tag'].str[2:] == label]\n",
    "\n",
    "    # All sentences containining those entities\n",
    "    sentences_with_entity = df.loc[df['SentenceNumber'].isin(df_label['SentenceNumber'])]\n",
    "\n",
    "    # Sequences squizzed into one row - preparation for augmenting operations\n",
    "    all_sentences_entities = sentences_with_entity\\\n",
    "        .groupby('EntityNumber')\\\n",
    "        .agg(Sentence=('Word', set_sentence), Label=('Tag', 'first'), SentenceNumber=('SentenceNumber', 'first'))\\\n",
    "        .reset_index()\n",
    "\n",
    "    # Dropping the sequences with no interest, they will not be augmented\n",
    "    if augment_only_this_label:\n",
    "        condition = all_sentences_entities['Label'].str[2:] != label\n",
    "    else:  \n",
    "        condition = all_sentences_entities['Label'] == 'O'\n",
    "    sentences_with_entity_to_aug = all_sentences_entities.loc[~condition]  \n",
    "    sentences_to_drop = sentences_with_entity_to_aug.loc[\n",
    "        sentences_with_entity_to_aug['Sentence'].apply(get_only_chars).str.len() == 0,\n",
    "        'SentenceNumber'\n",
    "    ]\n",
    "    \n",
    "    if mode == 'augmentation':\n",
    "        sentences_with_entity_to_aug = sentences_with_entity_to_aug.loc[\n",
    "            ~sentences_with_entity_to_aug['SentenceNumber'].isin(sentences_to_drop)\n",
    "        ]\n",
    "\n",
    "\n",
    "    # Augmentation\n",
    "    all_sentences_augmented = gen_fun(sentences_with_entity_to_aug, **gen_fun_args)\n",
    "\n",
    "    # List of augmentation indices\n",
    "    aug_versions = all_sentences_augmented['Version'].unique()\n",
    "    \n",
    "    # The sequences are being sorted and prepared for tokenization\n",
    "    ordered_augmented_sequences = pd.concat(\n",
    "        [prepare_original_dataset_to_add_augmentation(all_sentences_entities, i, condition) for i in aug_versions]+\n",
    "        [all_sentences_augmented]\n",
    "    ).sort_values(['Version', 'EntityNumber'])\n",
    "    \n",
    "    # Coming back to the original shape\n",
    "    all_sequences_augmented_expanded = tokenize_sentences_to_df(ordered_augmented_sequences)\n",
    "    all_sequences_augmented_expanded['SentenceNumber'] = all_sequences_augmented_expanded['SentenceNumber'].astype(str) + '-' + all_sequences_augmented_expanded['Version'].astype(str)\n",
    "    \n",
    "    return all_sequences_augmented_expanded[['SentenceNumber', 'Word', 'Tag', 'EntityNumber', 'Version']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed97b2a",
   "metadata": {},
   "source": [
    "#### Original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8021d8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceNumber</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>EntityNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>242</td>\n",
       "      <td>They</td>\n",
       "      <td>B-Referential-Term</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>242</td>\n",
       "      <td>are</td>\n",
       "      <td>O</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>242</td>\n",
       "      <td>short</td>\n",
       "      <td>B-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>242</td>\n",
       "      <td>,</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>242</td>\n",
       "      <td>hair</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>242</td>\n",
       "      <td>-</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>242</td>\n",
       "      <td>like</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>242</td>\n",
       "      <td>structures</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>242</td>\n",
       "      <td>that</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>242</td>\n",
       "      <td>are</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>242</td>\n",
       "      <td>used</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>242</td>\n",
       "      <td>to</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304</th>\n",
       "      <td>242</td>\n",
       "      <td>move</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>242</td>\n",
       "      <td>entire</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3306</th>\n",
       "      <td>242</td>\n",
       "      <td>cells</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SentenceNumber        Word                 Tag  EntityNumber\n",
       "3292             242        They  B-Referential-Term           268\n",
       "3293             242         are                   O           269\n",
       "3294             242       short        B-Definition           270\n",
       "3295             242           ,        I-Definition           270\n",
       "3296             242        hair        I-Definition           270\n",
       "3297             242           -        I-Definition           270\n",
       "3298             242        like        I-Definition           270\n",
       "3299             242  structures        I-Definition           270\n",
       "3300             242        that        I-Definition           270\n",
       "3301             242         are        I-Definition           270\n",
       "3302             242        used        I-Definition           270\n",
       "3303             242          to        I-Definition           270\n",
       "3304             242        move        I-Definition           270\n",
       "3305             242      entire        I-Definition           270\n",
       "3306             242       cells        I-Definition           270"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['SentenceNumber'] == 242].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e22f1738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-Term                      6611\n",
       "B-Definition                6062\n",
       "B-Alias-Term                 726\n",
       "B-Secondary-Definition       479\n",
       "B-Referential-Definition     308\n",
       "B-Qualifier                  162\n",
       "B-Referential-Term           140\n",
       "B-Definition-frag             85\n",
       "B-Term-frag                    8\n",
       "B-Ordered-Term                 5\n",
       "B-Ordered-Definition           5\n",
       "B-Alias-Term-frag              3\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Tag'].loc[df_train['Tag'].str.startswith('B')].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e3eb9",
   "metadata": {},
   "source": [
    "#### Augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7b7786a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_augmented_data = add_data(df_train, 'Referential-Term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f6da0b13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceNumber</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>EntityNumber</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>477-0</td>\n",
       "      <td>these</td>\n",
       "      <td>B-Referential-Term</td>\n",
       "      <td>570.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>477-0</td>\n",
       "      <td>speck</td>\n",
       "      <td>I-Referential-Term</td>\n",
       "      <td>570.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>477-0</td>\n",
       "      <td>supporter</td>\n",
       "      <td>B-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>477-0</td>\n",
       "      <td>to</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>477-0</td>\n",
       "      <td>diffuse</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>477-0</td>\n",
       "      <td>a</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>477-0</td>\n",
       "      <td>betoken</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>477-0</td>\n",
       "      <td>through</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>477-0</td>\n",
       "      <td>the</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>477-0</td>\n",
       "      <td>cytol</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>477-0</td>\n",
       "      <td>by</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>477-0</td>\n",
       "      <td>neuter</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>477-0</td>\n",
       "      <td>the</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>477-0</td>\n",
       "      <td>doings</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>477-0</td>\n",
       "      <td>of</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SentenceNumber       Word                     Tag  EntityNumber Version\n",
       "69          477-0      these      B-Referential-Term         570.0       0\n",
       "70          477-0      speck      I-Referential-Term         570.0       0\n",
       "71          477-0  supporter  B-Secondary-Definition         571.0       0\n",
       "72          477-0         to  I-Secondary-Definition         571.0       0\n",
       "73          477-0    diffuse  I-Secondary-Definition         571.0       0\n",
       "74          477-0          a  I-Secondary-Definition         571.0       0\n",
       "75          477-0    betoken  I-Secondary-Definition         571.0       0\n",
       "76          477-0    through  I-Secondary-Definition         571.0       0\n",
       "77          477-0        the  I-Secondary-Definition         571.0       0\n",
       "78          477-0      cytol  I-Secondary-Definition         571.0       0\n",
       "79          477-0         by  I-Secondary-Definition         571.0       0\n",
       "80          477-0     neuter  I-Secondary-Definition         571.0       0\n",
       "81          477-0        the  I-Secondary-Definition         571.0       0\n",
       "82          477-0     doings  I-Secondary-Definition         571.0       0\n",
       "83          477-0         of  I-Secondary-Definition         571.0       0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_augmented_data.loc[only_augmented_data['SentenceNumber'] == \"477-0\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ed758cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-Referential-Term        560\n",
       "B-Definition              520\n",
       "B-Term                     64\n",
       "B-Secondary-Definition     40\n",
       "B-Alias-Term               16\n",
       "B-Qualifier                 8\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_augmented_data['Tag'].loc[only_augmented_data['Tag'].str.startswith('B')].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907eadc9",
   "metadata": {},
   "source": [
    "####  Augmented data v2 \n",
    "Only the sequences of interest are augmented. Number of particular entities will not be changed in comparison with the previous approach but the non-augmented sentences are left as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d11d0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_augmented_data_v2 = add_data(df_train, 'Referential-Term', augment_only_this_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6dfe552c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceNumber</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>EntityNumber</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>477-1</td>\n",
       "      <td>these</td>\n",
       "      <td>B-Referential-Term</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>477-1</td>\n",
       "      <td>atom</td>\n",
       "      <td>I-Referential-Term</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>477-1</td>\n",
       "      <td>help</td>\n",
       "      <td>B-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>477-1</td>\n",
       "      <td>to</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>477-1</td>\n",
       "      <td>spread</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>477-1</td>\n",
       "      <td>a</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>477-1</td>\n",
       "      <td>signal</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>477-1</td>\n",
       "      <td>through</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>477-1</td>\n",
       "      <td>the</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>477-1</td>\n",
       "      <td>cytoplasm</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>477-1</td>\n",
       "      <td>by</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>477-1</td>\n",
       "      <td>altering</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>477-1</td>\n",
       "      <td>the</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>477-1</td>\n",
       "      <td>behavior</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137</th>\n",
       "      <td>477-1</td>\n",
       "      <td>of</td>\n",
       "      <td>I-Secondary-Definition</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SentenceNumber       Word                     Tag  EntityNumber Version\n",
       "4123          477-1      these      B-Referential-Term         570.0       1\n",
       "4124          477-1       atom      I-Referential-Term         570.0       1\n",
       "4125          477-1       help  B-Secondary-Definition         571.0       1\n",
       "4126          477-1         to  I-Secondary-Definition         571.0       1\n",
       "4127          477-1     spread  I-Secondary-Definition         571.0       1\n",
       "4128          477-1          a  I-Secondary-Definition         571.0       1\n",
       "4129          477-1     signal  I-Secondary-Definition         571.0       1\n",
       "4130          477-1    through  I-Secondary-Definition         571.0       1\n",
       "4131          477-1        the  I-Secondary-Definition         571.0       1\n",
       "4132          477-1  cytoplasm  I-Secondary-Definition         571.0       1\n",
       "4133          477-1         by  I-Secondary-Definition         571.0       1\n",
       "4134          477-1   altering  I-Secondary-Definition         571.0       1\n",
       "4135          477-1        the  I-Secondary-Definition         571.0       1\n",
       "4136          477-1   behavior  I-Secondary-Definition         571.0       1\n",
       "4137          477-1         of  I-Secondary-Definition         571.0       1"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_augmented_data_v2.loc[only_augmented_data_v2['SentenceNumber'] == \"477-1\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6e7accc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-Referential-Term        560\n",
       "B-Definition              520\n",
       "B-Term                     64\n",
       "B-Secondary-Definition     40\n",
       "B-Alias-Term               16\n",
       "B-Qualifier                 8\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_augmented_data_v2['Tag'].loc[only_augmented_data_v2['Tag'].str.startswith('B')].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0346cd",
   "metadata": {},
   "source": [
    "### Proposal of the final augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5fb368e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-Term                      6611\n",
       "B-Definition                6062\n",
       "B-Alias-Term                 726\n",
       "B-Secondary-Definition       479\n",
       "B-Referential-Definition     308\n",
       "B-Qualifier                  162\n",
       "B-Referential-Term           140\n",
       "B-Definition-frag             85\n",
       "B-Term-frag                    8\n",
       "B-Ordered-Term                 5\n",
       "B-Ordered-Definition           5\n",
       "B-Alias-Term-frag              3\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Tag'].loc[df_train['Tag'].str.startswith('B')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a042a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = [\n",
    "    add_data(df_train, 'Referential-Term', augment_only_this_label=True, num_adds=12),\n",
    "    add_data(df_train, 'Qualifier', augment_only_this_label=True, num_adds=8),\n",
    "    add_data(df_train, 'Referential-Definition', augment_only_this_label=True, num_adds=2, alpha_sr=0.2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "edff70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_augmentation = pd.concat([df_train] + augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b8e686c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-Term                      7943\n",
       "B-Definition                7244\n",
       "B-Referential-Definition     964\n",
       "B-Alias-Term                 870\n",
       "B-Referential-Term           848\n",
       "B-Qualifier                  840\n",
       "B-Secondary-Definition       593\n",
       "B-Definition-frag             89\n",
       "B-Term-frag                   24\n",
       "B-Alias-Term-frag             15\n",
       "B-Ordered-Term                 5\n",
       "B-Ordered-Definition           5\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_augmentation['Tag'].loc[data_with_augmentation['Tag'].str.startswith('B')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "048b8ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_augmentation[['SentenceNumber', 'Word', 'Tag']].to_csv('data/train_augmentation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb6fee",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c57edb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_data = [\n",
    "    add_data(df_train, 'Referential-Term', mode='oversampling',  num_adds=9),\n",
    "    add_data(df_train, 'Qualifier', mode='oversampling', num_adds=8),\n",
    "    add_data(df_train, 'Referential-Definition', mode='oversampling', num_adds=3),\n",
    "    add_data(df_train, 'Alias-Term', mode='oversampling', num_adds=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "150cbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_oversampling = pd.concat([df_train] + oversampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "80561ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B-Term                      9651\n",
       "B-Definition                8665\n",
       "B-Alias-Term                1700\n",
       "B-Qualifier                 1534\n",
       "B-Referential-Term          1420\n",
       "B-Referential-Definition    1344\n",
       "B-Secondary-Definition       694\n",
       "B-Definition-frag             98\n",
       "B-Term-frag                   41\n",
       "B-Alias-Term-frag             28\n",
       "B-Ordered-Term                 5\n",
       "B-Ordered-Definition           5\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_oversampling['Tag'].loc[data_with_oversampling['Tag'].str.startswith('B')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3e114987",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_oversampling[['SentenceNumber', 'Word', 'Tag']].to_csv('data/train_oversampling.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
